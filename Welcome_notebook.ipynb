{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import zipfile\n",
    "from torchvision import transforms\n",
    "from skimage.measure import compare_ssim as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple exploration of data structure and submission format.\n",
    "\n",
    "First of all, run downloader.py. It will create folder 'data' and download competition data and lists. Then unzip imgs.zip to data/imgs/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_imgs</th>\n",
       "      <th>target_imgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60f5fb295648e54bd1dc0c859c8fff620ee2eb40.jpg|b...</td>\n",
       "      <td>48f9c10f6e20153d752bbb7248016df80a16f4c3.jpg|2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3e15d19b62ba5c991e8a0d9f85ddb3d8adde9a31.jpg|9...</td>\n",
       "      <td>d53757cc366571251a74d4df211b05b67a279eb2.jpg|d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2cf2e394b1a4fa1d4f71a11deb5eaccfd757d668.jpg|2...</td>\n",
       "      <td>8f9faa1124481d2749ca5ec90c8762fb69a244b7.jpg|b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dcf724dec8125b19bbdc5ab328f3affcdd124a3a.jpg|b...</td>\n",
       "      <td>b57e0e26f0198f3c99626a704849c88506933959.jpg|2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>589b3c020dbebb39d52c874dee3c4b84c4ea031a.jpg|5...</td>\n",
       "      <td>76931fc56b77730739eb46ee00da61bd4ef30b83.jpg|d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_imgs  \\\n",
       "0  60f5fb295648e54bd1dc0c859c8fff620ee2eb40.jpg|b...   \n",
       "1  3e15d19b62ba5c991e8a0d9f85ddb3d8adde9a31.jpg|9...   \n",
       "2  2cf2e394b1a4fa1d4f71a11deb5eaccfd757d668.jpg|2...   \n",
       "3  dcf724dec8125b19bbdc5ab328f3affcdd124a3a.jpg|b...   \n",
       "4  589b3c020dbebb39d52c874dee3c4b84c4ea031a.jpg|5...   \n",
       "\n",
       "                                         target_imgs  \n",
       "0  48f9c10f6e20153d752bbb7248016df80a16f4c3.jpg|2...  \n",
       "1  d53757cc366571251a74d4df211b05b67a279eb2.jpg|d...  \n",
       "2  8f9faa1124481d2749ca5ec90c8762fb69a244b7.jpg|b...  \n",
       "3  b57e0e26f0198f3c99626a704849c88506933959.jpg|2...  \n",
       "4  76931fc56b77730739eb46ee00da61bd4ef30b83.jpg|d...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/pairs_list.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each line contains paths to 5 images of source id and 5 images of target id. All images are stored at 'data/imgs' folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = 'data/imgs/'\n",
    "os.listdir(imgs_path)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at some pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in df.index[:5]:\n",
    "    source_imgs = df.loc[idx].source_imgs\n",
    "    target_imgs = df.loc[idx].target_imgs\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    for i, img_name in enumerate(source_imgs.split('|'), 1):\n",
    "        img = Image.open(os.path.join(imgs_path,img_name))\n",
    "        plt.subplot(1, 10, i)\n",
    "        plt.title('S{}_Im{}'.format(idx,i))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        \n",
    "    for i, img_name in enumerate(target_imgs.split('|'), 1):\n",
    "        img = Image.open(os.path.join(imgs_path,img_name))\n",
    "        plt.subplot(1, 10, i+5)\n",
    "        plt.title('T{}_Im{}'.format(idx,i))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying black box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use black box, you should place BB file near your code or add it to your Path variable. Depending on your version of python and operating system download and store corresponding version of file. Here we use MCS2018.cpython-36m-x86_64-linux-gnu.so. Once you've done this, you should be able to import MCS2018 library:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MCS2018\n",
    "#import MCS2018_CPU as MCS2018 if you are using CPU only black box model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, create an instance of black box. Note, that if you have GPU available, you can specify GPU card number. If you're using CPU only, write -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 1\n",
    "net = MCS2018.Predictor(gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can get face descriptor from a photo. But first you need to preprocess image accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    MEAN = [0.485, 0.456, 0.406]\n",
    "    STD = [0.229, 0.224, 0.225]\n",
    "    preprocessing = transforms.Compose([\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.Resize(112),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=MEAN, std=STD),\n",
    "                    ])\n",
    "    img_arr = preprocessing(img).unsqueeze(0).numpy()\n",
    "    return img_arr\n",
    "img_arr = preprocess_img(img)\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_descriptor = net.submit(img_arr).squeeze()\n",
    "img_descriptor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance between descriptors of the same identity is small while distance between different persons is high:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_imgs = df.loc[0].source_imgs\n",
    "target_imgs = df.loc[0].target_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "source_desc=[]\n",
    "target_desc=[]\n",
    "for img_name in source_imgs.split('|'):\n",
    "    img = Image.open(os.path.join(imgs_path,img_name))\n",
    "    img_arr = preprocess_img(img)\n",
    "    source_desc.append(net.submit(img_arr).squeeze())\n",
    "    \n",
    "for img_name in target_imgs.split('|'):\n",
    "    img = Image.open(os.path.join(imgs_path,img_name))\n",
    "    img_arr = preprocess_img(img)\n",
    "    target_desc.append(net.submit(img_arr).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = lambda x, y: np.round(np.sqrt(((x - y) ** 2).sum(axis=0)),4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dist between S0_Im0 and S0_Imi:',list(map(dist,5*[source_desc[0]],source_desc)))\n",
    "print('Dist between S0_Im0 and T0_Imi:',list(map(dist,5*[source_desc[0]],target_desc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal is to modify source images so that the distance between modified source and target is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is 'small'? SSIM metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSIM metric shows the similarity between 2 images. For same images, SSIM=1. For different images -1 < SSIM < 0, SSIM -> 0. In this challenge we consider SSIM distance after Image preprocessing, but before mean/std normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_crop(img):\n",
    "    preprocessing = transforms.Compose([\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.Resize(112),\n",
    "                    ])\n",
    "    return preprocessing(img)\n",
    "\n",
    "\n",
    "def crop_to_tensor(img):\n",
    "    MEAN = [0.485, 0.456, 0.406]\n",
    "    STD = [0.229, 0.224, 0.225]\n",
    "    preprocessing = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=MEAN, std=STD),\n",
    "                    ])\n",
    "    img_arr = preprocessing(img).unsqueeze(0).numpy()\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imsave, imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name=source_imgs.split('|')[0]\n",
    "img = Image.open(os.path.join(imgs_path,img_name))\n",
    "img_crop = img_to_crop(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSIM metric is sensitive even to small changes in the image. For example, let's see what happens if we change it by using jpg compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_crop.save('tmp.png')\n",
    "img_crop.save('tmp.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_crop_jpg=Image.open('tmp.jpg')\n",
    "img_crop_png=Image.open('tmp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim(np.array(img_crop_jpg), np.array(img_crop_png), multichannel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance is also affected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_jpg=net.submit(crop_to_tensor(img_crop_jpg)).squeeze(0)\n",
    "des_png=net.submit(crop_to_tensor(img_crop_png)).squeeze(0)\n",
    "\n",
    "dist(des_jpg,des_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this challenge is about spoofing and not dealing with compression issues, you'll submit only png images. Now let's look at submission format in more details:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your submission file should consist of 5000 source png images as well as npy matrix with precalculated descriptors. This sounds strange but this is made to reduce load of evaluation server and to allow results appear quicker on leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a submission with unchanged images as an example. First of all, you need to save png source images. Note that you submit 112x112 crops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('submit_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_imgs_list = pd.read_csv('data/submit_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in source_imgs_list.path:\n",
    "    img = Image.open(os.path.join(imgs_path,img_path[:-3]+'jpg'))\n",
    "    img_crop = img_to_crop(img)\n",
    "    img_crop.save(os.path.join('submit_01',img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is sample submission and we do not change images. When you submit modified images, stick to this file names example. However, keep in mind that SSIM between modified images and original ones should not be less than 0.95 or your sumbission will fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's precompute descriptors for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = np.ones((5000, 512), dtype=np.float32)\n",
    "for idx, img_path in tqdm(enumerate(source_imgs_list.path.values), total=len(source_imgs_list.path.values)):\n",
    "    img = Image.open(os.path.join('submit_01', img_path))\n",
    "    img_arr = crop_to_tensor(img)\n",
    "    img_des = net.submit(img_arr).squeeze()\n",
    "    descriptors[idx] = img_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_path = 'submit_01/descriptors.npy'\n",
    "np.save(descriptors_path, descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_imgs_list_png = source_imgs_list.copy()\n",
    "source_imgs_list_png.path = source_imgs_list_png.path.apply(lambda x: x[:-3]+'png')\n",
    "\n",
    "\n",
    "if not os.path.isdir('./submits/'):\n",
    "    os.makedirs('./submits')\n",
    "submit_file = './submits/submit_01.zip'\n",
    "    \n",
    "with zipfile.ZipFile(submit_file,'w') as myzip:\n",
    "    for img_name in tqdm(source_imgs_list_png.path.values,\n",
    "                         desc='archive'):\n",
    "        myzip.write(os.path.join('submit_01', img_name), arcname=img_name)\n",
    "    myzip.write(descriptors_path, arcname='descriptors.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can submit created file to codalab server. Note that we'll run evaluation on submitted images sometimes to check that  descriptors match images. Participants who will submit different descriptors and images will be banned."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
